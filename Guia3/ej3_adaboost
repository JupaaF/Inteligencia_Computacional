from sklearn.model_selection import KFold, train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.datasets import load_wine
from sklearn.naive_bayes import GaussianNB
from sklearn import svm
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import VotingClassifier
# from tabulate import tabulate
import matplotlib.pyplot as plt
import numpy as np


# Función para calcular el error ponderado
def weighted_error(y_true, y_pred, weights):
    return np.sum(weights * (y_true != y_pred)) / np.sum(weights)

# Función para calcular el factor de ajuste alpha
def calculate_alpha(error):
    return 0.5 * np.log((1 - error) / (error + 1e-10))  # Evita divisiones por 0

# Función para actualizar los pesos
def update_weights(weights, alpha, y_true, y_pred):
    return weights * np.exp(-alpha * y_true * y_pred)

# Generar datos de juguete
np.random.seed(42)
X = np.random.randn(100, 2)
y = np.array([1 if x1 + x2 > 0 else -1 for x1, x2 in X])

# Inicializar pesos uniformes
n_samples = X.shape[0]
weights = np.ones(n_samples) / n_samples

# Número de clasificadores débiles
n_classifiers = 10

# Almacenar clasificadores y sus pesos
classifiers = []
alphas = []

# Lista de clasificadores débiles a usar
weak_classifiers = [
    DecisionTreeClassifier(max_depth=1),
    LogisticRegression(),
    KNeighborsClassifier(n_neighbors=3)
]

# Alternamos entre diferentes clasificadores débiles
for i in range(n_classifiers):
    # Seleccionamos el clasificador débil actual alternando entre los disponibles
    clf = weak_classifiers[i % len(weak_classifiers)]
    
    # Entrenamos el clasificador con los pesos actuales
    clf.fit(X, y, sample_weight=weights)
    
    # Predicción en los datos
    y_pred = clf.predict(X)
    
    # Calcular el error ponderado del clasificador
    error = weighted_error(y, y_pred, weights)
    
    # Calcular el factor de ajuste (alpha)
    alpha = calculate_alpha(error)
    
    # Guardamos el clasificador y su alpha
    classifiers.append(clf)
    alphas.append(alpha)
    
    # Actualizamos los pesos de los ejemplos
    weights = update_weights(weights, alpha, y, y_pred)
    
    # Normalizamos los pesos
    weights /= np.sum(weights)
    
    print(f"Iteración {i+1}: Clasificador = {type(clf).__name__}, Error ponderado = {error:.4f}, Alpha = {alpha:.4f}")

# Clasificación final basada en la combinación de todos los clasificadores
def adaboost_predict(X, classifiers, alphas):
    classifier_preds = np.array([alpha * clf.predict(X) for clf, alpha in zip(classifiers, alphas)])
    return np.sign(np.sum(classifier_preds, axis=0))

# Predicciones finales en los datos
y_pred_final = adaboost_predict(X, classifiers, alphas)

# Precisión del modelo
accuracy = np.mean(y_pred_final == y)
print(f"\nPrecisión del modelo: {accuracy:.4f}")

# Visualización de los resultados
plt.scatter(X[:, 0], X[:, 1], c=y_pred_final, cmap='bwr', edgecolor='k')
plt.title("AdaBoost - Resultado Final con Múltiples Clasificadores")
plt.show()





